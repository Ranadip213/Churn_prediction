{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxFmmd3-05Dd",
        "outputId": "024b86fc-7bb0-4425-f327-e06a4272513e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"TelcoChurnWithPySpark\").getOrCreate()"
      ],
      "metadata": {
        "id": "C3VY6ttM1F-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\", header=True, inferSchema=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW4LvgQy1OBC",
        "outputId": "ea9d52bc-d15e-4b7c-e3cd-a11c993fd337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|\n",
            "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|\n",
            "|3668-QPYBK|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|\n",
            "|7795-CFOCW|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|\n",
            "|9237-HQITU|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Rows:\", df.count(), \"Columns:\", len(df.columns))\n",
        "df.printSchema()\n",
        "df.groupBy(\"Churn\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5ooT5Bf1aY2",
        "outputId": "13b4d7d2-049d-4621-8bfd-06f51b0302a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 7043 Columns: 21\n",
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n",
            "+-----+-----+\n",
            "|Churn|count|\n",
            "+-----+-----+\n",
            "|   No| 5174|\n",
            "|  Yes| 1869|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.na.drop()\n",
        "df = df.withColumn(\"TotalCharges\", col(\"TotalCharges\").cast(\"float\"))"
      ],
      "metadata": {
        "id": "FGuh3fVu1kf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "\n",
        "categoricalCols = [c for c, t in df.dtypes if t == \"string\" and c not in [\"customerID\", \"Churn\"]]\n",
        "stages = []\n",
        "\n",
        "for col_name in categoricalCols:\n",
        "    idx = StringIndexer(inputCol=col_name, outputCol=col_name + \"Idx\")\n",
        "    enc = OneHotEncoder(\n",
        "        inputCols=[col_name + \"Idx\"],\n",
        "        outputCols=[col_name + \"Vec\"]\n",
        "    )\n",
        "    stages += [idx, enc]\n",
        "\n",
        "# Index the target\n",
        "label_indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\")\n",
        "stages += [label_indexer]\n",
        "\n",
        "# Assemble all features\n",
        "numericCols = [c for c, t in df.dtypes if t in [\"double\", \"int\", \"float\"]]\n",
        "assemblerInputs = [c + \"Vec\" for c in categoricalCols] + numericCols\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\", handleInvalid= \"keep\")\n",
        "stages += [assembler]\n"
      ],
      "metadata": {
        "id": "PoGTuop-1sGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline(stages=stages)\n",
        "model = pipeline.fit(df)\n",
        "df_transformed = model.transform(df)\n",
        "\n",
        "df_transformed.select(\"features\", \"label\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysQYWg3M1zTx",
        "outputId": "2a3e217b-9945-4865-d158-293185ba0f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|features                                                                                                                                       |label|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|(30,[2,7,8,11,12,14,16,18,20,22,23,27,28,29],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,29.85,29.850000381469727])                       |0.0  |\n",
            "|(30,[0,1,2,3,4,7,9,10,13,14,16,18,24,27,28,29],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,34.0,56.95,1889.5])                        |0.0  |\n",
            "|(30,[0,1,2,3,4,7,9,11,12,14,16,18,20,22,24,27,28,29],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,53.85,108.1500015258789])|1.0  |\n",
            "|(30,[0,1,2,7,9,10,13,15,16,18,25,27,28,29],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,45.0,42.3,1840.75])                                    |0.0  |\n",
            "|(30,[1,2,3,4,6,8,10,12,14,16,18,20,22,23,27,28,29],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,70.7,151.64999389648438])      |1.0  |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df_transformed.randomSplit([0.7, 0.3], seed=42)\n",
        "print(\"Train Rows:\", train.count(), \"Test Rows:\", test.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQZVEFjD17G5",
        "outputId": "0b89ae62-80b2-48ec-d7f5-196f00622136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Rows: 5036 Test Rows: 2007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "_NKW3tFO4LeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Don't overwrite \"label\", use another name first\n",
        "indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label_index\")\n",
        "df_indexed = indexer.fit(df_transformed).transform(df_transformed)\n",
        "\n",
        "# If you want \"label\" specifically, rename later\n",
        "df_indexed = df_indexed.withColumnRenamed(\"label_index\", \"label\")\n"
      ],
      "metadata": {
        "id": "33z6zDfc4NTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df_indexed.randomSplit([0.7, 0.3], seed=42)\n",
        "print(\"Train Rows:\", train.count(), \"Test Rows:\", test.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88HfNVtX5pGF",
        "outputId": "d0641185-0de3-4dc7-837d-49a4cbeebd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Rows: 5036 Test Rows: 2007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Convert Churn into numeric label (0/1)\n",
        "indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\")\n",
        "df_indexed = indexer.fit(df_indexed).transform(df_indexed)\n"
      ],
      "metadata": {
        "id": "HHAbTIVm6KI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_indexed.select(\"features\", \"label\")\n"
      ],
      "metadata": {
        "id": "Fq8mtSbE50P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df_final.randomSplit([0.7, 0.3], seed=42)\n"
      ],
      "metadata": {
        "id": "xsTpLyDJ7TBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Replace empty strings in TotalCharges with null, then drop rows with nulls\n",
        "df = df.withColumn(\"TotalCharges\",\n",
        "                   col(\"TotalCharges\").cast(\"double\"))\n",
        "\n",
        "# Drop rows with NaN or nulls\n",
        "df = df.na.drop()\n"
      ],
      "metadata": {
        "id": "FaWNRU-37XtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"ChurnPrediction\").getOrCreate()\n",
        "\n",
        "# --- Load dataset ---\n",
        "df = spark.read.csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# --- Data Cleaning ---\n",
        "# Convert TotalCharges to double and drop null rows\n",
        "df = df.withColumn(\"TotalCharges\", col(\"TotalCharges\").cast(\"double\"))\n",
        "df = df.na.drop()\n",
        "\n",
        "# --- Index categorical columns ---\n",
        "categorical_cols = [col for col, dtype in df.dtypes if dtype == \"string\" and col != \"Churn\"]\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\").fit(df) for col in categorical_cols]\n",
        "\n",
        "for indexer in indexers:\n",
        "    df = indexer.transform(df)\n",
        "\n",
        "# --- Index target column (Churn) ---\n",
        "label_indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\").fit(df)\n",
        "df = label_indexer.transform(df)\n",
        "\n",
        "# --- Assemble features ---\n",
        "feature_cols = [c+\"_index\" for c in categorical_cols] + [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# --- Train-test split ---\n",
        "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "print(f\"Train Rows: {train_data.count()} Test Rows: {test_data.count()}\")\n",
        "\n",
        "# --- Train Logistic Regression Model ---\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "# --- Predictions ---\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# --- Evaluate Model ---\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy = {accuracy:.4f}\")\n",
        "\n",
        "# --- Save Model ---\n",
        "model_path = \"/content/model/logistic_regression_churn\"\n",
        "lr_model.save(model_path)\n",
        "print(f\"✅ Model saved at {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIqfI_4U7vQT",
        "outputId": "5528f0c3-f9d7-4bd8-93ef-1e98463236b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Rows: 5028 Test Rows: 2004\n",
            "Test Accuracy = 0.8129\n",
            "✅ Model saved at /content/model/logistic_regression_churn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.classification import LogisticRegressionModel\n",
        "import random\n",
        "\n",
        "# -------------------------\n",
        "# Step 0: Start Spark session\n",
        "# -------------------------\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionTest\").getOrCreate()\n",
        "\n",
        "# -------------------------\n",
        "# Step 1: Load pre-trained Logistic Regression model\n",
        "# -------------------------\n",
        "model_path = \"/content/model/logistic_regression_churn\"  # Update path if needed\n",
        "model = LogisticRegressionModel.load(model_path)\n",
        "\n",
        "# Get expected number of features\n",
        "num_features = model.numFeatures\n",
        "print(f\"Model expects {num_features} features per sample.\")\n",
        "\n",
        "# -------------------------\n",
        "# Step 2: Create synthetic test data\n",
        "# -------------------------\n",
        "# Create 10 samples with correct feature size\n",
        "data = []\n",
        "for _ in range(10):\n",
        "    features = [random.uniform(0, 3) for _ in range(num_features)]\n",
        "    label = float(random.randint(0, 1))  # Ensure label is float\n",
        "    data.append(Row(features=Vectors.dense(features), label=label))\n",
        "\n",
        "test_df = spark.createDataFrame(data)\n",
        "\n",
        "# -------------------------\n",
        "# Step 3: Run predictions\n",
        "# -------------------------\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# -------------------------\n",
        "# Step 4: Show results\n",
        "# -------------------------\n",
        "predictions.select(\"features\", \"label\", \"probability\", \"prediction\").show(truncate=False)\n",
        "\n",
        "# -------------------------\n",
        "# Step 5: Stop Spark session\n",
        "# -------------------------\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YQcGbAhCEOE",
        "outputId": "150bed3f-d98c-4531-aee6-f066ba53ffbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model expects 19 features per sample.\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------------------------+----------+\n",
            "|features                                                                                                                                                                                                                                                                                                                                                                |label|probability                              |prediction|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------------------------+----------+\n",
            "|[1.843075915686816,0.31717392703591163,1.003549444401589,0.8950523944335971,0.9875015726462933,1.6635496864015313,1.3671131355179322,0.9264191979281621,1.9134265512458757,2.3955107225690515,2.7636333678507126,0.1721973710549647,2.4566826403966475,2.3185170303162757,2.6483933732487426,2.3208876995504824,1.486258150076195,2.655386253800382,1.827488603571532]  |0.0  |[0.8744689336404947,0.12553106635950528] |0.0       |\n",
            "|[1.9330739960095036,0.6294544767911004,0.6348040143354661,0.5113780598392957,1.4532226499793566,0.2575977727960227,1.9843789358074777,2.0174152521683917,0.9890640637349156,2.871627845091451,0.41501695777838044,1.1466913539660821,1.5380069698051355,1.1887832997913397,0.6416524561465607,2.25142676490366,0.7302954770062756,1.4282479453849533,2.880240176486336] |0.0  |[0.8247846499350073,0.17521535006499267] |0.0       |\n",
            "|[2.5044933519244124,0.4923472174232487,1.9787481091381125,0.06778990380340377,1.5476553001113063,0.8679591783422096,0.059017866658247375,2.178127481125199,1.5787547260217907,1.4672837376021701,2.621571403322218,2.987829890122818,2.9471187462103376,0.7725012348956956,1.7019172855625908,0.3848691065060732,2.260608412507277,2.966299831602059,1.7275987260300378]|0.0  |[0.2712625213698693,0.7287374786301307]  |1.0       |\n",
            "|[1.8731168221283911,0.9524434437536355,1.9624623721724448,1.7274100730705029,0.05848863006563454,0.3209786715881553,2.3604583119363354,0.9989076703336182,0.4728406424335948,2.6738682846643345,2.356592666037719,1.17681877227167,0.4092794170016505,1.8173738227870238,2.9916600148829566,1.3946137287177782,0.7570548367821947,1.1762232940684254,2.8341071693357835]|0.0  |[0.9694449933327511,0.030555006667248863]|0.0       |\n",
            "|[2.053130059419835,1.036385974690991,2.793701103688991,1.2367205518581748,0.19200713423748028,2.9225585816786603,2.28363820883591,0.2165027543733139,0.8912254264041469,2.851025251897318,1.831205806082946,2.9450910966874777,2.6468264635284626,2.6804129948653435,2.825527645220878,2.8121727983665994,0.416117895809645,0.48917289674725595,1.8666039536988248]     |0.0  |[0.7036141028429238,0.2963858971570762]  |0.0       |\n",
            "|[0.1373553419199086,2.3022424221531854,0.40423978217283674,1.7520753972435035,1.6413372017696346,0.6332341307200018,2.802677427265546,1.4566071602398039,2.359926117330747,0.06971524342428015,2.630126578246154,0.7997935805641053,2.35998349032529,1.576974845156713,0.9695699353631337,0.0859561311385737,1.1960001275586056,1.2740235544971463,0.9566193589171655]  |1.0  |[0.9523002507007512,0.047699749299248806]|0.0       |\n",
            "|[1.2873433856916598,2.029313573731616,1.4710563341038043,2.4310404674573083,0.6179402251409084,0.2800321046916413,1.1733131173246507,1.7041656004960362,1.8374169504023732,2.082836913760951,0.1267859022047675,2.3643763700947837,2.458823548271096,0.1634545316358016,0.005302853736703361,2.093464350165874,2.4011828116882294,1.3268843270374489,2.655523054338992] |0.0  |[0.33818716201229626,0.6618128379877037] |1.0       |\n",
            "|[0.3845791150411113,0.9569392451462466,0.1494602427286844,1.7854634311936226,2.5882463732660055,2.0007554806306027,0.32088183958730065,1.5352971547550123,2.7550886704428326,2.745847496378714,2.964619944420823,2.9861803651827152,0.8623917894987787,2.912531833382665,1.2389396976879294,0.2928386616230847,1.4401312784672844,1.254352568109237,0.2847095713071661] |0.0  |[0.7059962764807064,0.2940037235192936]  |0.0       |\n",
            "|[2.046220946125964,1.310571059465043,0.22935111025466726,0.07935726691882494,0.13397655107767337,2.3545166650230787,0.3132303981869021,0.3656171367441484,2.760141749711325,0.9114515380358046,1.1710461769628306,1.7316703936451203,1.189115678437821,2.012957820788686,0.5370227524633355,1.8596882422410554,1.249582586633271,2.0457613970460033,2.2428672240439242] |0.0  |[0.1804928000390697,0.8195071999609302]  |1.0       |\n",
            "|[2.4215102737200995,2.0553531998282497,2.7647235005223827,1.24229371225932,2.202513403487209,1.9764540814045108,0.25772820537443863,1.197822568760151,0.648969206694028,0.32360402014781,0.6917211077673168,0.4344110729006295,2.667884654054062,1.6261941567191607,2.172527177336572,1.9264628919206301,2.8793489395862917,1.1517501290725534,0.39544513523461955]     |0.0  |[0.39257313445538083,0.6074268655446191] |1.0       |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------------------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}